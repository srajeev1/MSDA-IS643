---
title: "DATA 643 - Project 2"
author: "Sreejaya Nair, Suman K Polavarapu"
date: "June 25, 2016"
output: html_document
---

###Build a basic recommender system with multiple recommender configurations

####Description

This system recommends  movies to users using different recommendation algorithms and evaluates those different approaches.
The data source is Movielens dataset.

####Load the data & Analyse

__Load the required libraries__
```{r, warning=FALSE, message=FALSE}
## load libraries ####
library(recommenderlab)
library(reshape2)
library(RCurl)
library(dplyr)
library(ggplot2)
```


__Data Acquisition & Clean up__

*Load the required data - movies and ratings *
```{r}
#Read the Movie data
moviesurl <- getURL("https://raw.githubusercontent.com/srajeev1/MSDA-IS643/master/projects/project1/ml-latest-small/movies.csv")
moviesDF <- read.csv(text = moviesurl,header = TRUE, stringsAsFactors = FALSE)
knitr::kable(head(moviesDF))

## read Ratings data, remove timestamp column.
ratingsurl <- getURL("https://raw.githubusercontent.com/srajeev1/MSDA-IS643/master/projects/project1/ml-latest-small/ratings.csv")
ratingDF <- read.csv(text = ratingsurl,header = TRUE, stringsAsFactors = FALSE)
ratingDF <- ratingDF %>% select(userId, movieId, rating)
knitr::kable(head(ratingDF))
```

*Reshape the data*
```{r}
ratingDF_horizontal <-acast(ratingDF, userId ~ movieId, value.var="rating")

#Lets find the top 3 movies by mean rating.
cmn <- colMeans(ratingDF_horizontal, na.rm = TRUE)
nd <- order(cmn, decreasing = TRUE)
moviesDF %>% filter(movieId %in% nd[1:3])
```

*Prepare ratings matrix*

```{r}
# Convert ratingDF_horizontal into realRatingMatrix data structure
# realRatingMatrix is a recommenderlab sparse-matrix like data-structure

(ratingDF.ratingMatrix <- as(as.matrix(ratingDF_horizontal), "realRatingMatrix"))

#. Users who have rated at least 10 movies
#. Movies that have been watched at least 20 times
ratingDF.ratingMatrix <- ratingDF.ratingMatrix[rowCounts(ratingDF.ratingMatrix) > 10,colCounts(ratingDF.ratingMatrix) > 20] 

```

####Visualize and Normalize

```{r}
#mean user ratings
hist(rowMeans(ratingDF.ratingMatrix), breaks=100, main="Histogram of Mean User Ratings", xlab="Ratings", col= "light blue")

#mean rating for eash show
hist(colMeans(ratingDF.ratingMatrix), breaks=100, main="Histogram of Mean Movie Ratings", xlab="Ratings", col= "light green")

min_movies <- quantile(rowCounts(ratingDF.ratingMatrix), 0.98)
min_users <- quantile(colCounts(ratingDF.ratingMatrix), 0.98)

# build the heatmap:
image(ratingDF.ratingMatrix[rowCounts(ratingDF.ratingMatrix) > min_movies,colCounts(ratingDF.ratingMatrix) > min_users], main = "Heatmap of the top users and movies")

ratingMatrix.normalized <- normalize(ratingDF.ratingMatrix)

# visualize the Normalized top matrix
min_movies <- quantile(rowCounts(ratingMatrix.normalized), 0.98)
min_users <- quantile(colCounts(ratingMatrix.normalized), 0.98)

# build the heatmap:
image(ratingMatrix.normalized[rowCounts(ratingMatrix.normalized) > min_movies,colCounts(ratingMatrix.normalized) > min_users], main = "Heatmap of the top users and movies")
```

####Split the data frame into training and test

```{r}
## 75% of the sample size
smp_size <- floor(0.75 * nrow(ratingMatrix.normalized))
set.seed(123)
train_ind <- sample(seq_len(nrow(ratingMatrix.normalized)), size = smp_size)

train.RatingMat <- ratingMatrix.normalized[train_ind, ]
test.RatingMat <- ratingMatrix.normalized[-train_ind, ]

```

####Model Building

Lets build models using different recommender configurations, like UBCF (User Based Collab Filtering, Item Based Collab Filtering, with various similarity methods like Cosine, Jaccard)

```{r, warning=FALSE, message=FALSE}
createModel <-function (movieRatingMat,method, param)
{
  
  model <- Recommender(movieRatingMat, method = method, param)
  names(getModel(model))
  getModel(model)$method
  getModel(model)$nn
  print(model)  
  
  return (model)
}


#UBCF, Cosine similarity
ubd.rec=createModel(train.RatingMat, method="UBCF", param=list(normalize = "Z-score",method="Cosine",nn=5, minRating=1))


#UBCF, Jaccard similarity
ubd.rec.jac=createModel(train.RatingMat, method="UBCF", param=list(normalize = "Z-score",method="Jaccard",nn=5, minRating=1))


#IBCF, Jaccard similarity
ibcf.rec.jac=createModel(train.RatingMat, method="IBCF", param=list(normalize = "Z-score",method="Jaccard",nn=5, minRating=1))
```


####Recommendations

Generate recommendation(s) leveraging the above models: 

Recommend top 3 movies for a given user.
```{r, warning=FALSE, message=FALSE}
recommendations <- function(movieRatingMat, model, userID, n)
{
  
  ### predict top n recommendations for given user
  topN_recommendList <-predict(model,movieRatingMat[userID],n=n) 
  topN_recommendList@items[[1]]
  return(topN_recommendList)
  
}


#Let us get the top 3 recommendations for user 1, Using UBCF - Cosine Similarity
userID <- 1
topN <- 3
predict_list <-recommendations(train.RatingMat, ubd.rec, userID, topN)
predict_list@items[[1]]
subset(moviesDF, movieId %in% predict_list@items[[1]])

#Let us get the top 3 recommendations for user 1, Using UBCF - Jaccard Similarity
predict_list <-recommendations(train.RatingMat, ubd.rec.jac, userID, topN)
predict_list@items[[1]]
subset(moviesDF, movieId %in% predict_list@items[[1]])


#Let us get the top 3 recommendations for user 1 using IBCF Model
predict_list <-recommendations(train.RatingMat, ibcf.rec.jac, userID, topN)
predict_list@items[[1]]
subset(moviesDF, movieId %in% predict_list@items[[1]])
```


####Evaluation

Let's evaluate different recommender algorithms and see what performs best for our ratings matrix:
```{r}
scheme <- evaluationScheme(ratingDF.ratingMatrix, method = "split", train = .9, given = 4, goodRating = 4)
algorithms <- list(
  "random items" = list(name="RANDOM", param=list(normalize = "Z-score")),
  "popular items" = list(name="POPULAR", param=list(normalize = "Z-score")),
  "user-based CF" = list(name="UBCF", param=list(normalize = "Z-score",
                                                 method="Cosine",
                                                 nn=10, minRating=3)),
  "item-based CF" = list(name="IBCF", param=list(normalize = "Z-score")))

 
 

# run algorithms, predict next n movies
results1 <- evaluate(scheme, algorithms, n=c(1, 3, 5, 10, 15, 20))

#Draw ROC curve [true positive rate (Sensitivity) is plotted in function of the false positive rate (100-Specificity) for different cut-off points]
recommenderlab::plot(results1, annotate = 1:4, legend="topleft")


# See precision / recall
recommenderlab::plot(results1, "prec/rec", annotate=3)
```

####Conclusion

From the above evaluation it seems like the UBCF did  better than the IBCF. 
RANDOM items approach is the worst here, but surprisingly the POPULAR items did the best here!

